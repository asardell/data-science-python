# Formation Data Science avec Python  
**Durée : 3 jours — Théorie + Pratique + Mini-projets**  
**Dataset principal : Données DPE issues de l’API ADEME**

## Objectifs de la formation

Cette formation a pour but de donner aux participants les **bases solides** et les **bonnes pratiques** nécessaires pour :

- Manipuler Python pour la Data Science  
- Explorer, nettoyer et visualiser des données  
- Comprendre et appliquer les principaux algorithmes de Machine Learning  
- Évaluer et optimiser des modèles  
- Construire une interface utilisateur simple (Streamlit)  
- Emballer et déployer un modèle dans un conteneur Docker  

À l’issue de la formation, les participants seront capables de **réaliser un projet de Machine Learning de bout en bout**, depuis les données brutes jusqu’au modèle utilisable.

## Public visé

- Développeurs  
- Data analysts  
- Débutants en Data Science / Python  
- Toute personne souhaitant acquérir les fondamentaux  
- Niveau maths : lycée (minimum recommandé)

## Enjeux pédagogiques

La formation répond à des besoins concrets en entreprise :  
- Comprendre les données et les transformer en valeur  
- Apprendre à utiliser les outils standards de l’écosystème Python  
- Maîtriser la logique des modèles supervisés / non supervisés  
- Savoir documenter, structurer et déployer un modèle ML  

L’objectif est d’être **100% opérationnel** à l’issue du parcours.

# Contexte du jeu de données ADEME (DPE)

Tout au long de la formation, nous travaillerons avec un dataset fourni par l’**ADEME** (Agence de la transition écologique), contenant les résultats des **Diagnostics de Performance Énergétique (DPE)**.

Ces données représentent :  
- des bâtiments (maison, appartement, immeuble)  
- leurs caractéristiques (année, surface, isolation…)  
- leurs consommations énergétiques  
- leurs émissions de gaz à effet de serre  
- leurs coûts énergétiques  
- leur diagnostic final (étiquette DPE, étiquette GES)

Ce dataset est idéal pour la formation car :  
- Il contient **plus de 200 variables** → parfait pour l’exploration  
- Il mélange **variables qualitatives** et **quantitatives**  
- Il permet de créer des cas réels de régression, classification, clustering  
- Il nécessite un vrai travail de **préparation**, comme en entreprise  

## Compétences développées pendant la formation

- Comprendre les fondamentaux de la Data Science  
- Utiliser les librairies Python : **NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn**  
- Effectuer un prétraitement complet : nettoyage, normalisation, encodage  
- Construire et évaluer des modèles :  
  - régressions  
  - classification  
  - clustering  
  - réduction de dimension  
- Optimiser un modèle (cross-validation, hyperparamètres)  
- Expliquer un modèle (SHAP)  
- Préparer un modèle pour la production  
- Créer une interface utilisateur (Streamlit)  
- Conteneuriser un projet ML avec Docker  

## Programme de la formation

Cette formation couvre les bases et les applications avancées de la **data science** avec Python, en suivant un parcours progressif :

1. **Introduction**  
   - `1-Introduction-data-science.md` : Concepts fondamentaux de la data science.  
   - `2-Introduction-python.md` : Premiers pas avec Python pour l'analyse de données.  

2. **Python et bonnes pratiques**  
   - `3-Bonnes-pratiques-python.md` : Écriture de code Python propre et maintenable.  
   - `4-Manipuler-des-donnees.md` : Gestion et transformation de données.  
   - `5-Visualisation.md` : Création de graphiques et visualisations pertinentes.  
   - `6-Preparation-des-donnnes.md` : Préparation et nettoyage des données.  

3. **Méthodes et algorithmes**  
   - `7-Méthodes-factorielles.md` : Analyse factorielle et réduction de dimensions.  
   - `8-Clustering.md` : Regroupement et segmentation de données.  
   - `9-Classification.md` : Algorithmes de classification.  
   - `10-Régression.md` : Régression linéaire et avancée.  
   - `11-Perceptrons.md` : Réseaux de neurones simples.  

4. **Thèmes avancés**  
   - `12-Interpretabilites-modeles.md` : Explicabilité et interprétation des modèles.  
   - `13-MLops.md` : Déploiement et gestion de modèles en production.  
   - `14-Text-Mining.md` : Analyse de texte et NLP.  
   - `15-Reinforcement Learning.md` : Apprentissage par renforcement.  
   - `16-Spark.md` : Traitement distribué avec Apache Spark.  

Chaque chapitre est conçu pour être autonome et progresser de la théorie vers la pratique avec des exemples concrets en Python.


## Ressources utilisées

- **Python 3.10+**  
- **Jupyter Notebook**  
- **VSCode**

## Liens utiles :

- [Challenge ENEDIS](https://defis.data.gouv.fr/defis/65b76f15d7874915c8e41298/)